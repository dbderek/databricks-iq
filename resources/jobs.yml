resources:
  jobs:
    databricks-lakespend-data-refresh:
      name: databricks-lakespend-data-refresh
      # Run this job once an hour.
      trigger:
        periodic:
          interval: 4
          unit: HOURS
      tasks:
        - task_key: refresh_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.databricks-lakespend-data.id}       
      queue:
        enabled: true
        
      performance_target: PERFORMANCE_OPTIMIZED

    databricks-lakespend-create-agent:
      name: create-databricks-lakespend-agent
      tasks:
        - task_key: run_agent_driver
          notebook_task:
            notebook_path: ../src/agent/driver.py
            base_parameters:
              sp_client_id: ${var.sp_client_id}
              sp_secret_scope: ${var.sp_secret_scope}
              sp_secret_key: ${var.sp_secret_key}
              catalog: ${var.catalog}
              schema: ${var.schema}
      queue:
        enabled: true
      performance_target: PERFORMANCE_OPTIMIZED
    